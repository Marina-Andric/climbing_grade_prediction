{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline, KNNWithMeans, KNNBasic, BaselineOnly, KNNWithZScore\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from surprise import SVDpp\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_for_grades = {'vl-0': 0, 'vl-1': 1, 'vl-2': 2, 'vl-3': 2, 'vl-4': 3, 'vl-5': 3, 'vl-6': 4, 'vl-7': 4, 'vl-8': 4, 'vl-9': 5, 'vl-10': '5a', 'vl-11': '5a+', 'vl-12': '5b', 'vl-13': '5b+', 'vl-14': '5c', 'vl-15': '5c+', 'vl-16': '6a', 'vl-17': '6a+', 'vl-18': '6b', 'vl-19': '6b+', 'vl-20': '6b+', 'vl-21': '6c', 'vl-22': '6c+', 'vl-23': '7a', 'vl-24': '7a+', 'vl-25': '7b', 'vl-26': '7b+', 'vl-27': '7c', 'vl-28': '7c+', 'vl-29': '8a', 'vl-30': '8a+', 'vl-31': '8b', 'vl-32': '8b+', 'vl-33': '8c', 'vl-34': '8c+', 'vl-35': '9a', 'vl-36': '9a+', 'vl-37': '9b', 'vl-38': '9b+', 'vl-39': '9c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise library implementation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_ds_0_4_rand_42.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRAIN_routes - routes for outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = 'data/train_ds_0_2.csv'\n",
    "#'data/TRAIN_routes_v1.csv'\n",
    "\n",
    "#'data/train_ds_0_2.csv' \n",
    "#'data/train_ds_ds_v7_allhist.csv'\n",
    "#'data/train_ds_ds_v7_single_time_all_hist.csv'\n",
    "test_file_name = 'data/test_ds_0_2.csv'\n",
    "#'data/TEST_routes_v1.csv'\n",
    "#'data/test_ds_0_4_rand_42.csv'\n",
    "#'data/test_ds_0_2.csv'\n",
    "#'data/test_ds_ds_v7_allhist.csv'\n",
    "#'data/test_ds_ds_v7_single_time_all_hist.csv'\n",
    "df_train_svd = pd.read_csv(train_file_name)\n",
    "df_test_svd = pd.read_csv(test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_svd['diff'] = df_train_svd['user_grade_id'] - df_train_svd['grade_id'] + 4\n",
    "df_test_svd['diff'] = df_test_svd['user_grade_id'] - df_test_svd['grade_id'] + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "mmin, mmax = 1, 7\n",
    "reader = Reader(rating_scale=(mmin, mmax))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_train_svd[['user_id','route_id','diff']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset_model_surprise = Dataset.load_from_df(df_test_svd[['user_id','route_id','diff']], reader).build_full_trainset()\n",
    "trainset_model_surprise = Dataset.load_from_df(df_train_svd[['user_id','route_id','diff']], reader)\n",
    "# testset = testset_model_surprise.build_testset()\n",
    "testset = df_test_svd[['user_id','route_id','diff']].values\n",
    "trainset = trainset_model_surprise.build_full_trainset()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train and test datasets\n",
    "trainset = data.build_full_trainset()\n",
    "testset = df_test_svd[['user_id','route_id','diff']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ALS\n",
      "reg_i:  3\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2649\n",
      "MSE: 1.5999\n",
      "MAE:  1.1252\n"
     ]
    }
   ],
   "source": [
    "print('Using ALS')\n",
    "bsl_options_als = [\n",
    "\n",
    "    {\n",
    "        'method': 'als',\n",
    "        'n_epochs': 100,\n",
    "        'reg_u': 5,\n",
    "        'reg_i': 3\n",
    "    }\n",
    "]\n",
    "for bsl_options_al in bsl_options_als:\n",
    "    print('reg_i: ', bsl_options_al['reg_i'])\n",
    "    algo = BaselineOnly(bsl_options=bsl_options_al)\n",
    "    predictions = algo.fit(trainset).test(testset)\n",
    "\n",
    "    accuracy.rmse(predictions)\n",
    "    accuracy.mse(predictions)\n",
    "    accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_svd[['user_id', 'route_id', 'SVD_prediction']].to_csv('data/test_ds_0_2_SVD_predictions.csv', index=False)\n",
    "#df_test_svd[['user_id', 'route_id', 'SVD_prediction']].to_csv('data/test_ds_0_4_rand_42_SVD_predictions.csv', index=False)\n",
    "df_test_svd[['user_id', 'route_id', 'SVD_prediction']].to_csv('data/TEST_routes_v1_SVD_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_train_svd[['user_id','route_id','diff']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [20, 30, 50],\n",
    "              'n_factors': [20, 30, 40, 100],\n",
    "              'biased': [True],\n",
    "              'lr_bu': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'lr_bi': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'lr_pu': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'lr_qi': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'reg_bu': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'reg_bi': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'reg_pu': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "              'reg_qi': [0.5, 0.1, 0.05, 0.005, 0.001, 0.0001],\n",
    "             }\n",
    "                                               \n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the suitable parameters made via cross validation, paste them and run trhe code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epochs:  40  lr_bu:  0.001  lr_bi:  0.001  lr_pu:  0.1  lr_qi:  0.1\n",
      "reg_bu:  0.5  reg_bi:  0.5  reg_pu:  0.1  reg_qi:  0.05\n",
      "MAE: 0.102\n",
      "MSE : 0.095\n",
      "RMSE: 0.307\n"
     ]
    }
   ],
   "source": [
    "list_lr = [3, 0.5, 0.1, 0.05, 0.005, 0.001, 0.0001]\n",
    "list_reg = [0.75, 0.5, 0.1, 0.05, 0.036, 0.001, 0.0001]\n",
    "list_lr_bu = [0.001]\n",
    "list_lr_bi = [0.001]\n",
    "list_lr_pu = [0.1]\n",
    "list_lr_qi = [0.1]\n",
    "list_reg_bu = [0.5]\n",
    "list_reg_bi = [0.5]\n",
    "list_reg_pu = [0.1]\n",
    "list_reg_qi = [0.05]\n",
    "list_epochs = [40]\n",
    "for epochs_ in list_epochs:\n",
    "    for lr_bu_ in list_lr_bu:\n",
    "        for lr_bi_ in list_lr_bi:\n",
    "            for lr_pu_ in list_lr_pu:\n",
    "                for lr_qi_ in list_lr_qi:\n",
    "                    for reg_bu_ in list_reg_bu:\n",
    "                        for reg_bi_ in list_reg_bi:\n",
    "                            for reg_pu_ in list_reg_pu:\n",
    "                                for reg_qi_ in list_reg_qi:\n",
    "                                    algo = SVD(n_factors=40, # The number of factors. Default is 100.\n",
    "                                               n_epochs=epochs_, # The number of iteration of the SGD procedure. Default is 20.\n",
    "                                               biased = True, # Whether to use baselines (or biases). See note above. Default is True.\n",
    "                                               init_mean =0, # The mean of the normal distribution for factor vectors initialization. Default is 0.\n",
    "                                               init_std_dev=0.1, # The standard deviation of the normal distribution for factor vectors initialization.\n",
    "                                                                   # Default is 0.1.\n",
    "                                               lr_all=0.005, # The learning rate for all parameters. Default is 0.005.\n",
    "                                               reg_all=0.1, # The regularization term for all parameters. Default is 0.02.\n",
    "                                               lr_bu=lr_bu_, # The learning rate for 𝑏𝑢.\n",
    "                                               lr_bi=lr_bi_, #\n",
    "                                               lr_pu=lr_pu_, #\n",
    "                                               lr_qi=lr_qi_, #\n",
    "                                               reg_bu=reg_bu_, #\n",
    "                                               reg_bi=reg_bi_, #\n",
    "                                               reg_pu=reg_pu_, #\n",
    "                                               reg_qi=reg_qi_ #\n",
    "                                              )\n",
    "                                    algo.fit(trainset)\n",
    "                                    # Evaluation\n",
    "                                    predictions = algo.test(testset)\n",
    "                                    print(' epochs: ', epochs_, ' lr_bu: ', lr_bu_, ' lr_bi: ', lr_bi_, ' lr_pu: ', lr_pu_, ' lr_qi: ', lr_qi_)\n",
    "                                    print('reg_bu: ', reg_bu_, ' reg_bi: ', reg_bi_, ' reg_pu: ', reg_pu_, ' reg_qi: ', reg_qi_)\n",
    "                                    print(f'MAE: {accuracy.mae(predictions, verbose=False):.3f}')\n",
    "                                    print(f'MSE : {accuracy.mse(predictions, verbose=False):.3f}')\n",
    "                                    print(f'RMSE: {accuracy.rmse(predictions, verbose=False):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
